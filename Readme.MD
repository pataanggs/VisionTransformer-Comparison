# Vision Transformer Comparison

Proyek penelitian yang membandingkan performa tiga arsitektur Vision Transformer state-of-the-art: **ViT (Vision Transformer)**, **DeiT (Data-efficient Image Transformer)**, dan **Swin Transformer** pada dataset STL-10.

ðŸ“š **Mata Kuliah**: Pembelajaran Mendalam (IF25-40401)  
ðŸ‘¨â€ðŸ« **Dosen**: Imam Eko Wicaksono, S.Si., M.Si. & Martin Clinton Tosima Manullang, S.T., M.T., Ph.D.

## ðŸŽ¯ Tujuan Penelitian

Penelitian ini bertujuan untuk:

1. Membandingkan performa akurasi dari tiga arsitektur Vision Transformer (ViT, DeiT, Swin)
2. Menganalisis efisiensi komputasi (training time, inference time, throughput)
3. Mengevaluasi trade-off antara akurasi dan efisiensi untuk aplikasi praktis
4. Memberikan rekomendasi pemilihan model berdasarkan skenario penggunaan

## ðŸ“Š Dataset

**STL-10 Dataset**

- **Jumlah Kelas**: 10 (airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck)
- **Resolusi Input**: 224 Ã— 224 piksel (diubah dari asli 96 Ã— 96)
- **Pembagian Data**:
  - Training: 4,000 gambar
  - Validation: 1,000 gambar
  - Test: 8,000 gambar

**Augmentasi Data**:

- Random Horizontal Flip (50%)
- Random Rotation (Â±15Â°)
- Color Jitter (brightness & contrast: 0.2)
- Normalisasi ImageNet (mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225])

## ðŸ—ï¸ Arsitektur Model

| Model         | Parameter | Ukuran | Karakteristik Utama                     |
| ------------- | --------- | ------ | --------------------------------------- |
| **ViT Base**  | 85.8M     | 327 MB | Pure transformer, patch-based attention |
| **DeiT Base** | 85.8M     | 327 MB | Knowledge distillation, data-efficient  |
| **Swin Base** | 86.8M     | 332 MB | Hierarchical, shifted window attention  |

Semua model menggunakan **pre-trained weights** dari ImageNet dan di-fine-tune pada STL-10.

## ðŸ”§ Konfigurasi Training

```python
Optimizer          : AdamW
Learning Rate      : 3e-5
Batch Size         : 64
Epochs             : 20
Loss Function      : Cross Entropy Loss
LR Scheduler       : Cosine Annealing (T_max=20)
Weight Decay       : 0.05
Mixed Precision    : Enabled (torch.cuda.amp)
```

**Hardware**:

- GPU: NVIDIA A40 (44 GB VRAM)
- CPU: 9 vCores
- RAM: 50 GB
- Platform: RunPod Cloud

## ðŸ“ˆ Hasil Eksperimen

### Ringkasan Performa

| Model         | Test Accuracy | Macro F1   | Training Time | Inference/Img | Throughput  |
| ------------- | ------------- | ---------- | ------------- | ------------- | ----------- |
| **DeiT Base** | 98.11%        | 0.9811     | 5.5 menit     | 2.56 ms       | 389.9 img/s |
| **ViT Base**  | 99.08%        | 0.9907     | 5.5 menit     | 2.57 ms       | 388.8 img/s |
| **Swin Base** | **99.36%**    | **0.9936** | 8.5 menit     | 3.42 ms       | 292.6 img/s |

### Kesimpulan Utama

âœ… **Swin Transformer**: Akurasi tertinggi (99.36%), cocok untuk aplikasi yang memprioritaskan akurasi  
âœ… **ViT Base**: Keseimbangan terbaik antara akurasi (99.08%) dan kecepatan inferensi  
âœ… **DeiT Base**: Tercepat dalam inferensi (389.9 img/s), cocok untuk real-time applications

## ðŸ“ Struktur Proyek

```
VisionTransformer-Comparison/
â”œâ”€â”€ chapters/                    # Bab-bab Laporan LaTeX
â”‚   â”œâ”€â”€ cover.tex               # Halaman cover
â”‚   â”œâ”€â”€ 01_pendahuluan.tex      # BAB I: Pendahuluan
â”‚   â”œâ”€â”€ 02_landasan_teori.tex   # BAB II: Landasan Teori
â”‚   â”œâ”€â”€ 03_metodologi.tex       # BAB III: Metodologi
â”‚   â”œâ”€â”€ 04_hasil_analisis.tex   # BAB IV: Hasil dan Analisis
â”‚   â”œâ”€â”€ 05_kesimpulan.tex       # BAB V: Kesimpulan dan Saran
â”‚   â””â”€â”€ 06_lampiran.tex         # LAMPIRAN
â”œâ”€â”€ code/                        # Kode Eksperimen
â”‚   â”œâ”€â”€ 122140055_VisionTransformerComparison.ipynb  # Notebook utama
â”‚   â”œâ”€â”€ requirements.txt         # Dependencies
â”‚   â”œâ”€â”€ DeiT_Base_history.csv   # Training log DeiT
â”‚   â”œâ”€â”€ ViT_Base_history.csv    # Training log ViT
â”‚   â”œâ”€â”€ Swin_Base_history.csv   # Training log Swin
â”‚   â”œâ”€â”€ final_summary.csv       # Ringkasan hasil
â”‚   â””â”€â”€ detailed_metrics.txt    # Metrik detail per kelas
â”œâ”€â”€ Figure/                      # Visualisasi dan Gambar
â”‚   â”œâ”€â”€ *_Accuracy_Trend.pdf    # Grafik akurasi
â”‚   â”œâ”€â”€ *_Loss_Trend.pdf        # Grafik loss
â”‚   â”œâ”€â”€ *_Confusion_Matrix.pdf  # Confusion matrices
â”‚   â”œâ”€â”€ learning_curves.pdf     # Learning curves
â”‚   â”œâ”€â”€ training_log*.png       # Screenshot training logs
â”‚   â””â”€â”€ *.pdf                   # Diagram arsitektur
â”œâ”€â”€ main.tex                     # Dokumen LaTeX utama
â”œâ”€â”€ Referensi.bib               # File bibliografi
â””â”€â”€ Readme.MD                   # File ini
```

## ðŸš€ Cara Menjalankan

### 1. Setup Environment

```bash
cd code/
pip install -r requirements.txt
```

### 2. Jalankan Eksperimen

Buka dan jalankan notebook:

```bash
jupyter notebook 122140055_VisionTransformerComparison.ipynb
```

Atau jalankan di Google Colab/RunPod untuk akses GPU.

### 3. Kompilasi Dokumen LaTeX

```bash
# Dari root directory
pdflatex -shell-escape main.tex
bibtex main
pdflatex -shell-escape main.tex
pdflatex -shell-escape main.tex
```

**Note**: Flag `-shell-escape` diperlukan untuk package `minted` dan `svg`.

## ðŸ“¦ Dependencies

**Python Libraries**:

- PyTorch >= 2.0.0
- torchvision >= 0.15.0
- timm (PyTorch Image Models)
- NumPy, Pandas
- Matplotlib, Seaborn
- scikit-learn

**LaTeX Packages**:

- minted (syntax highlighting)
- svg (SVG image support)
- hyperref, graphicx, amsmath, booktabs, dll.

Lihat `code/requirements.txt` untuk daftar lengkap dependencies Python.

## ðŸ“„ Metrik Evaluasi

1. **Accuracy**: Persentase prediksi benar
2. **Precision, Recall, F1-Score**: Per-class performance
3. **Confusion Matrix**: Visualisasi prediksi vs ground truth
4. **Training Time**: Waktu total training (20 epochs)
5. **Inference Time**: Rata-rata waktu per gambar (ms)
6. **Throughput**: Jumlah gambar diproses per detik
7. **Model Size**: Total parameters dan ukuran file (MB)

## ðŸ“š Referensi Utama

1. Dosovitskiy et al. (2020) - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
2. Touvron et al. (2021) - Training Data-Efficient Image Transformers
3. Liu et al. (2021) - Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
4. Vaswani et al. (2017) - Attention is All You Need
