% BAB II - LANDASAN TEORI
\section{Landasan Teori}

\subsection{Transformer dan Self-Attention}
% Tulis penjelasan singkat tentang Transformer dan Self-Attention di sini
% Contoh:
% Transformer adalah arsitektur neural network yang diperkenalkan oleh Vaswani et al. (2017) dalam paper "Attention is All You Need"...
% 
% Self-attention mechanism memungkinkan model untuk...

\subsection{Arsitektur Model yang Dibandingkan}

\subsubsection{Model 1: [Nama Model]}
% Deskripsi arsitektur model pertama
% Contoh: Vision Transformer (ViT)
% - Struktur patch embedding
% - Jumlah transformer blocks
% - Dimensi hidden layer
% - dll.

\subsubsection{Model 2: [Nama Model]}
% Deskripsi arsitektur model kedua
% Contoh: DeiT (Data-efficient Image Transformer)

\subsubsection{Model 3: [Nama Model]}
% Deskripsi arsitektur model ketiga
% Contoh: Swin Transformer

% Tambahkan model lain sesuai kebutuhan

\subsection{Perbedaan Kunci Antar Model}
% Tulis perbedaan kunci antara model-model yang dibandingkan
% Contoh:
% \begin{itemize}
%     \item \textbf{Patch Size}: ViT menggunakan patch 16x16, sedangkan...
%     \item \textbf{Attention Mechanism}: Swin Transformer menggunakan shifted window attention...
%     \item \textbf{Training Strategy}: DeiT menggunakan distillation token...
% \end{itemize}

\subsection{Kelebihan dan Kekurangan Masing-Masing Model}

\subsubsection{Model 1}
\textbf{Kelebihan:}
\begin{itemize}
    \item % Kelebihan 1
    \item % Kelebihan 2
\end{itemize}

\textbf{Kekurangan:}
\begin{itemize}
    \item % Kekurangan 1
    \item % Kekurangan 2
\end{itemize}

\subsubsection{Model 2}
\textbf{Kelebihan:}
\begin{itemize}
    \item % Kelebihan 1
    \item % Kelebihan 2
\end{itemize}

\textbf{Kekurangan:}
\begin{itemize}
    \item % Kekurangan 1
    \item % Kekurangan 2
\end{itemize}

% Tambahkan untuk model lainnya
